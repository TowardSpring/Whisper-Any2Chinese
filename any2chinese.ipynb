{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune the whisper to realize the any2chinese task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whisper模型是OpenAI推出的语音识别模型，该模型支持多种语言的语音识别，将其转录为对应语言文本。同时，该模型还有翻译功能，能将多种语言的语音转录为英文文本。在Whisper模型诞生之后，很多开源项目对其进行了微调或改进，使得模型能够在小语种上语音识别能力得到了进一步的增强，并且在C语言编译、PEFT等技术的加持下，Whisper模型现在可以在小设备上加速运行。\n",
    "\n",
    "但是，当前，还鲜有看到有项目进一步的开发Whisper对新语种语音转录功能，或者进一步微调模型使其支持将各种语言的语音直接转录为中文文本。显然，这将进一步的发掘模型的潜力。\n",
    "\n",
    "本教程借助transformers包收录的Whisper模型，在其基础上对该模型的tokenizer进行了修改。这样使得Whisper模型具备转录新语种以及直接转录为中文文本的能力。本教程将该方法命名为Whisper-Any2Chinese模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/towardspring/opt/anaconda3/envs/whisper/lib/python3.9/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login, login\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from pprint import pprint\n",
    "from transformers import WhisperFeatureExtractor\n",
    "import os\n",
    "from transformers import WhisperTokenizer\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "from datasets import Audio\n",
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "import evaluate\n",
    "from transformers import WhisperForConditionalGeneration,Seq2SeqTrainingArguments\n",
    "from peft import prepare_model_for_int8_training,LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model,PeftModel, PeftConfig\n",
    "from transformers import Seq2SeqTrainer, TrainerCallback, TrainingArguments, TrainerState, TrainerControl,WhisperForConditionalGeneration, Seq2SeqTrainer\n",
    "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\n",
    "\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efcfdd1a1794530ac050457e7b1f090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在微调模型之前，你需要准备好训练数据。训练数据的格式以及数据的元信息文件如本教程的“./data/*”中的两个数据集所示。其中“en_mini”表示英文数据集（包含对应的转录中文），“ug_mini”表示维语数据集（包含对应的转录中文）。你可以根据自己的需求，准备好自己的数据集。本教程的数据来自于commonvoice数据集，你可以在[这里](https://commonvoice.mozilla.org/)下载到该数据集。（只做demo，因此本教程的数据集只包含了很少的数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403a9de668dc41dd9f14f816a734defb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188ebc03042b49f49cb2b96f376dcc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a7508aab5c450795760cb0f745fce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'sentence', 'chinese'],\n",
      "        num_rows: 55\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'sentence', 'chinese'],\n",
      "        num_rows: 12\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['audio', 'sentence', 'chinese'],\n",
      "        num_rows: 15\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "common_voice = DatasetDict()\n",
    "\n",
    "dataset_name_or_path = \"./data/ug_mini\"\n",
    "language = \"uyghur\"\n",
    "language_abbr = \"ug\" # Short hand code for the language we want to fine-tune\n",
    "\n",
    "common_voice[\"train\"] = load_dataset(dataset_name_or_path, split=\"train\")\n",
    "common_voice[\"test\"] = load_dataset(dataset_name_or_path, split=\"test\")\n",
    "common_voice[\"validation\"] = load_dataset(dataset_name_or_path, split=\"validation\")\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_name_or_path = \"openai/whisper-small\"   # you can choose any size of model by your service's capability\n",
    "task = \"translate\"\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=language_abbr, task=task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whisper本身是不支持添加新语种或者多语言中文转录功能。因此，我们需要在微调之前，添加新的语种标签以及中文转录翻译提示标签。例如，若想实现对维吾尔语的转录，我们需要向tokenizer模块添加<|ug|>标签；若想实现对多语种的中文转录翻译功能，需要向tokenizer模块添加<|translate-chinese|>标签。本教材只对英语语音转录翻译中文文本做出示范，您可以根据您的需要添加任意语音或翻译标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
